{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 4 Submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Develop API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "## Import any other packages that are needed\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 1. Load your model here\n",
    "model = joblib.load(...)\n",
    "\n",
    "# 2. Define a prediction function\n",
    "def return_prediction(...):\n",
    "\n",
    "    # format input_data here so that you can pass it to model.predict()\n",
    "\n",
    "    return model.predict(...)\n",
    "\n",
    "# 3. Set up home page using basic html\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    # feel free to customize this if you like\n",
    "    return \"\"\"\n",
    "    <h1>Welcome to our rain prediction service</h1>\n",
    "    To use this service, make a JSON post request to the /predict url with 25 climate model outputs.\n",
    "    \"\"\"\n",
    "\n",
    "# 4. define a new route which will accept POST requests and return model predictions\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def rainfall_prediction():\n",
    "    content = request.json  # this extracts the JSON content we sent\n",
    "    prediction = return_prediction(...)\n",
    "    results = {...}  # return whatever data you wish, it can be just the prediction\n",
    "                     # or it can be the prediction plus the input data, it's up to you\n",
    "    return jsonify(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Deploy App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Summarize Journey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 1:\n",
    "\n",
    "We downloaded a large dataset from figshare and discovered that the speed of combining the separate csv files and loading the entire dataset differs greatly on all our devices. From there, we explored different methods of loading the dataset including partitioning the dataset and retrieving only the columns that we need and found this not only sped up the process but also saved us memory usage. We also tried changing the data type of the columns of the dataset but the memory and time saved was not as great. \n",
    "\n",
    "Lastly, we found using Apache arrow with all its great features for working with large datasets significantly improved the speed of transferring dataframes between Python and R.\n",
    "\n",
    "Milestone 2: \n",
    "\n",
    "We transitioned from working locally to working on the cloud using Amazon Web Services. We set up an Amazon EC2 instance with JupyterHub and added credentials for each user. We also set up our s3 bucket which offers high storage capacity to read and store our data from the previous milestone. We conducted further data wrangling using Parquet and its properties (projection pushdown and predicate pushdown) to prepare for the machine learning process.\n",
    "\n",
    "Milestone 3: \n",
    "\n",
    "We retrieved from our s3 bucket the wrangled data we prepared for machine learning and split it into train and test splits. We performed fundamental EDA for summary statistics and visualized distribution of each column. We then fit a RandomForestRegressor model on our data splits to find train and test RMSE scores. \n",
    "\n",
    "To see if we can better these scores, we set up an EMR cluster and EMR notebook to utilize PySpark for hyperparameter tuning our model. We got better RMSE scores using this tuned model and saved it for use in Milestone 4. \n",
    "\n",
    "Milestone 4:\n",
    "\n",
    "In our final milestone, we deployed our machine learning model. We started by developing the API and copying it into an ​​app.py file in our EC2 instance. We learned how to use Flask to get our machine learning model running in the cloud for others to use. \n",
    "\n",
    "To summarize, from this project, we’ve learned about the limitations of working with big data locally and steps we can take to decrease these storage and time costs. We’ve learned the steps of creating a server for a collaborative environment for our team and moving our data into the cloud. Finally, we learned about setting up a Spark cluster for developing our machine learning model and how to deploy it in the cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "525",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
